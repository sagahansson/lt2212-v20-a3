{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t grade3 -fs 13 -nf opensans -nfs 13 -N -kl -cursw 5 -cursc r -cellw 1800 -T -ofs 13 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv(\"a_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"Train/Test\"] == \"Train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=train_df.iloc[:,1:] #removes \"Test/Train column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df[\"Train/Test\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True, drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get author name\n",
    "d1_df = df.iloc[2928]\n",
    "d1_df[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also get author name\n",
    "d1_df = df[df.index == 2928]\n",
    "author1 = d1_df['Author']\n",
    "author1 = author1.values[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "allt ovan är bara läsa in df i två olika df's => test och train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "for i in range(batch_size):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filename = df.drop(\"Filename\", axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(batchsize, df):\n",
    "    \n",
    "    tens_labels = [] # list of tuples where each tuple contains a concatenated tensor and its label (0 for not same author, 1 for same author)\n",
    "    \n",
    "    for i in range(batchsize):\n",
    "        #make batches i e if batchsize is 5 => put 5 examples. each example (vector1, vector2, 0/1 (depending on wether or not vecto1 and 2 are by the same author)\n",
    "        authors = df.Author.unique().tolist() #get unique authors\n",
    "        first_author = authors.pop(random.randrange(0,len(authors))) # skaffa en random author\n",
    "        t_f = random.choice([0, 1]) # 0 = not from same author, 1 same author\n",
    "        if t_f == 1: \n",
    "            second_author = first_author\n",
    "        else: # if t_f is 0 \n",
    "            second_author = authors.pop(random.randrange(0,len(authors))) # skaffa en annan random author\n",
    "\n",
    "        author1_tensor = torch.from_numpy(df[df[\"Author\"] == first_author].sample(n=1).drop([\"Train/Test\", \"Author\"], axis=1).values) # picking a random row where Author = first_author, dropping the Train/Test and Author columns, converting to a ndarray, then to a tensor\n",
    "        author2_tensor = torch.from_numpy(df[df[\"Author\"] == second_author].sample(n=1).drop([\"Train/Test\", \"Author\"], axis=1).values)\n",
    "    \n",
    "        tensors = torch.cat((author1_tensor, author2_tensor), 0) # concatenating the two author tensors\n",
    "        \n",
    "        tens_labels.append((tensors, t_f)) # adding the label of the tensors i e if they're by the same auhtor or not\n",
    "        \n",
    "    return tens_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampling(5, train_df)\n",
    "tensor = [x[0] for x in samples]\n",
    "label = [x[1] for x in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = df.Author.unique().tolist()\n",
    "print(len(authors))\n",
    "first_author = authors.pop(random.randrange(0,(len(authors))))\n",
    "print(len(authors))\n",
    "print(first_author)\n",
    "second_author = authors.pop(random.randrange(0,(len(authors))))\n",
    "print(len(authors))\n",
    "print(second_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"Author\"].values == \"bailey-s\"]\n",
    "\n",
    "row = np.random.choice(df.index.values) # random int picking the row out of all available rows\n",
    "sampled_row = df.iloc[row] # the random row picked incl \"Train/Test\" and \"Author\", type 'pandas.core.series.Series' \n",
    "sampled = sampled_row[2:] # random row picked without \"Train/Test\" and \"Author\", type 'pandas.core.series.Series'\n",
    "sampled_list = sampled.tolist() # random row as list\n",
    "sampled_tensor = torch.Tensor(sampled_list) # random row as torch.Tensor\n",
    "\n",
    "sampled_tensor_oneliner = torch.Tensor((sampled_row[2:]).tolist()) # lines 5,6,7 as one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_row = train_df[train_df[\"Author\"] == first_author].sample(n=1, random_state=1) # pandas df w one randomly picked row, incl \"Train/Test\" and \"Author\"\n",
    "one_row_minus = one_row.drop([\"Train/Test\", \"Author\"], axis=1) # pandas df w one randomly picked row, EXCL \"Train/Test\" and \"Author\"\n",
    "one_values = one_row_minus.values[0] # numpy.ndarray w one randomly picked row, incl \"Train/Test\" and \"Author\"\n",
    "one_torch = torch.from_numpy(one_values) # torch.Tensor w one randomly picked row, incl \"Train/Test\" and \"Author\"\n",
    "\n",
    "\n",
    "one_oneliner = torch.from_numpy(df[df[\"Author\"].values == first_author].sample(n=1).drop([\"Train/Test\", \"Author\"], axis=1).values) # lines 1, 2, 3, 4 as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "y = torch.randn(2, 3)\n",
    "print(y)\n",
    "z = torch.randn(2, 3)\n",
    "print(z)\n",
    "torch.cat((one_oneliner, one_oneliner), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_data(size, df):\n",
    "    def compare_author(i1, i2):\n",
    "        d1_df = df[df.index == i1]\n",
    "        d2_df = df[df.index == i2]\n",
    "        author1 = d1_df['0']\n",
    "        a1 = author1.values.tolist()\n",
    "        author2 = d2_df['0']\n",
    "        a2 = author2.values.tolist()\n",
    "        d1 = d1_df.values.tolist()\n",
    "        d1 = d1[0][3:]\n",
    "        d2 = d2_df.values.tolist()\n",
    "        d2 = d2[0][3:]\n",
    "        if a1 == a2:\n",
    "            c = 1\n",
    "        else:\n",
    "            c = 0\n",
    "        d = d1 + d2\n",
    "        sample = (d, c)\n",
    "        return sample\n",
    "\n",
    "    samples = []\n",
    "    counter1 = 0\n",
    "    counter0 = 0\n",
    "    while len(samples) <= size:\n",
    "        index1 = random.choice(df.index)\n",
    "        index2 = random.choice(df.index)\n",
    "        while index1 == index2:\n",
    "            index2 = random.choice(df.index)\n",
    "        sample = compare_author(index1, index2)\n",
    "        if sample[1] == 1:\n",
    "            if counter1 <= size/2 + 1:\n",
    "                samples.append(sample)\n",
    "                counter1 += 1\n",
    "        else:\n",
    "            if counter0 <= size/2 + 1:\n",
    "                samples.append(sample)\n",
    "                counter0 += 1\n",
    "    random.shuffle(samples)\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledata(5, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://www.youtube.com/watch?v=oSirQZ_L7Q8&t=2s\n",
    "\n",
    "import torch\n",
    "from torch import autograd, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 5\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "num_classes = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "target = autograd.Variable((torch.rand(batch_size) * num_classes).long())\n",
    "input = autograd.Variable(torch.rand(batch_size, input_size))\n",
    "print(\"input:\", input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(input_size, hidden_size)\n",
    "        self.h2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.h1(x)\n",
    "        x = self.h2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    out = model(input)\n",
    "    _, pred = out.max(1)\n",
    "    print(\"target: \", target)\n",
    "    print(\"pred:\", pred)\n",
    "    loss = F.nll_loss(out, target)\n",
    "    print(\"loss:\", loss.data)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
